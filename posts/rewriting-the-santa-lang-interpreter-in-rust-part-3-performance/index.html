<!doctype html>
<html lang="en">
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="This series of posts documents my experience rewriting the santa-lang interpreter in Rust. In this post, I delve into how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way.">

    <title>
        
            Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance &middot; Edd Mann
        
    </title>

    <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPQ7WHNXH4"></script>
    <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments);}
       gtag('js', new Date());
       gtag('config', 'G-ZPQ7WHNXH4');
    </script>

    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="/styles.css">

    <link rel="shortcut icon" href="/favicon.ico">

    <link rel="alternate" href="/rss.xml" title="" type="application/rss+xml">

    
</head>

    <body>
        <div class="container content">
            <header class="masthead">
                <h3 class="masthead-title">
                    <a href="/" title="Home">Edd Mann</a>
                    <small><i class="fa fa-code"></i> Developer</small>
                </h3>
                <nav>
                    <a href="https://twitter.com/edd_mann"><i class="fa fa-twitter"></i></a>
                    <a href="https://github.com/eddmann"><i class="fa fa-github"></i></a>
                    <a href="mailto:the@eddmann.com"><i class="fa fa-envelope"></i></a>
                </nav>
                <div class="cf"></div>
            </header>

            <main>
                <article class="post">
    <h1 class="post-title">Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance</h1>
    <time datetime="2023-08-07T00:00:00+00:00" class="post-date">07 Aug 2023</time>
    <p>Now that we have discussed building the core language and desired runtimes, it is time to highlight one of the biggest reasons why I decided to rewrite the interpreter in a lower-level systems language - performance!
In this post, I will document how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way.</p>



<p>All benchmarks require a stable base, and as such, I decided to concentrate my efforts on the CLI runtimes.
This runtime is the one I use the most whilst developing Advent of Code solutions over the course of December.</p>

<h2 id="sizing-it-up">Sizing It Up…</h2>

<p>The first point that struck me was how much smaller the Rust binary artifact was - 3.8MB vs 47MB.
This is a bit of an unfair comparison as the TypeScript version is required to package up the entire <a href="https://www.npmjs.com/package/pkg">Node runtime</a> in order to be self-executable.
However, it did show how much smaller the same behaviour could be modelled in.
I was able to reduce the Rust binary size further using several <a href="https://nnethercote.github.io/perf-book/build-configuration.html">build configuration options</a>: <code class="language-plaintext highlighter-rouge">strip</code>, <code class="language-plaintext highlighter-rouge">codegen-units</code>, <code class="language-plaintext highlighter-rouge">lto</code>.</p>

<h2 id="initial-benchmarks">Initial Benchmarks</h2>

<p>Thanks to solving the <a href="https://eddmann.com/posts/solving-the-advent-of-code-2022-calendar-using-my-own-programming-language-santa-lang/">Advent of Code 2022</a> calendar in santa-lang, I had a good suite of examples for benchmarking the two variants.
Coupled with this, I included some simple examples which documented common language constructs that were present within the language, i.e., arithmetic, recursion, and looping.
One such example used recursion to compute the <em>nth</em> term in the Fibonacci sequence:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>let fibonacci = |n| if n &lt; 2 { n } else { fibonacci(n - 1) + fibonacci(n - 2) };
fibonacci(20);
</code></pre></div></div>

<p>Another example included a large arithmetic operation to test how the interpreter coped with parsing and evaluating such an expression.
I also included an example which was an empty file to baseline the interpreter’s fixed overheads.
To provide reliable benchmark results for these examples, I used <a href="https://github.com/sharkdp/hyperfine">hyperfine</a> with the following configuration:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hyperfine
    -n ts "./santa-cli-ts fibonacci.santa"
    -n rs "./santa-cli-rs fibonacci.santa"
    --time-unit millisecond
    --warmup 3
    --export-json fibonacci.json
    --runs 10
</code></pre></div></div>

<p>With this framework in place, I went on to perform my initial round of benchmarks on the two variants and was shocked by the results.
Several Rust example executions resulted in expected significant performance gains compared to the Node variant, thanks in large part to the quicker initialisation times and lighter-weight evaluator <code class="language-plaintext highlighter-rouge">Object</code> model.
However, there were many cases where the Node variant outperformed the Rust version - and not by small margins?!</p>

<h2 id="lets-get-profiling">Let’s Get Profiling</h2>

<p>It was at this time that I delved deeper into the Rust implementation, instrumenting my <a href="https://github.com/tikv/pprof-rs">code</a> to profile how much time was spent at each step.
I additionally spent some time adding the ability to produce <a href="https://www.brendangregg.com/flamegraphs.html">flame graphs</a>, which allow you to clearly visualise the profile output:</p>

<p><img src="/uploads/rewriting-the-santa-lang-interpreter-in-rust/flamegraph.png" alt="Flame graph" /></p>

<h3 id="infix-operators">Infix Operators</h3>

<p>Looking at these initial flame graphs led me to several changes in how infix operators were executed.
As the language supports the use of these operators within infix position as well as by function call, I had provided this functionality by way of shared Rust built-in function definitions.
This incurred a function invocation per infix operator, so instead, I opted to <a href="https://nnethercote.github.io/perf-book/inlining.html">inline</a> these functions.
Paying attention to not being hit by CPU cache performance penalties, I noticed the needless function stack allocations disappear.
Although this did help with performance, it still was not the boost that I had been hoping for, so the journey continued…</p>

<h3 id="environment-variables">Environment Variables</h3>

<p>The next step I took was to replace the <a href="https://nnethercote.github.io/perf-book/hashing.html">hash map implementation</a> I used within the environment that holds scoped variables.
I had noticed that time was spent resolving these environment variables, so I explored replacing the inbuilt hash map with a quicker (although less cryptographically secure) alternative, <a href="https://github.com/cbreeden/fxhash">FxHashMap</a>.
This again did not reap the rewards that I had been hoping for, and instead, thanks to a <a href="https://www.dannyvankooten.com/blog/2022/rewriting-interpreter-rust/">very interesting post</a>, I opted to use a vector to represent the environment variables.
This provided quicker variable resolution, whereby it was, interestingly, more performant to traverse a sequential list in memory than apply a hash and resolve the variable from a determined <em>bucket</em>.
This performance improvement was based on the code heuristic that there would be a limited number of variables per scope.
Sadly, after additional benchmarking, this chipped away some execution time, but I was still not satisfied.</p>

<h3 id="memory-allocation">Memory Allocation</h3>

<p>I thought I needed to take a different approach and turned my attention to the Node variant.
One train of thought I had was that maybe the Node’s performance was better for some use cases due to the included just-in-time compiler (JIT), with ‘hot paths’ being compiled to native code.
To check this, I explored <a href="https://v8.dev/blog/jitless">disabling the Node JIT</a> and was amazed at how much less performant it was.
Perhaps this was as far as I could go with a simple tree-walking interpreter…</p>

<p>All my benchmarks to date had been performed on macOS, and to garner additional insights into my performance woes, I decided to use a Linux tool, <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a>.
What surprised me when I ran the examples on Linux was how much more performant they were - they were blowing the performance of the Node variant out of the water!?
After closer inspection, I pinpointed that this was due to the different default memory heap allocators used in the two operating systems.
Linux was using <a href="https://jemalloc.net/">jemalloc</a>, touted for reducing memory fragmentation, which is invaluable when performing many small memory heap allocations like santa-lang does.
Due to this finding, I changed the <a href="https://crates.io/crates/tikv-jemallocator">default Rust allocator</a> and was able to see a comparable performance increase when executing the solutions on macOS!</p>

<p>I felt like this was a good place to stop tuning the interpreter for performance at this time and enjoy the performance improvements that I had managed to achieve to date.</p>

<h2 id="final-benchmarks">Final Benchmarks</h2>

<p>With all the performance tuning out of the way (for the time being), it was time to see how much more performant the Rust variant was compared to its TypeScript compatriot.
Below is a graph (created using <a href="https://matplotlib.org/">Matplotlib</a>) benchmarking the example scripts I used to model typical language feature usage:</p>

<p><img src="/uploads/rewriting-the-santa-lang-interpreter-in-rust/standard-benchmark.png" alt="Standard Benchmark" /></p>

<p>Visualising the benchmarks for the Advent of Code solutions proved to be a bit trickier due to some solutions being orders of magnitude slower than others.
As such, I broke these findings into two graphs, the first using milliseconds as the unit of measurement:</p>

<p><img src="/uploads/rewriting-the-santa-lang-interpreter-in-rust/aoc-2022-benchmark-1.png" alt="Advent of Code 2022 Benchmark 1" /></p>

<p>And the second graph using seconds as the unit of measurement:</p>

<p><img src="/uploads/rewriting-the-santa-lang-interpreter-in-rust/aoc-2022-benchmark-2.png" alt="Advent of Code 2022 Benchmark 2" /></p>

<p>As you can see, in all cases, the Rust interpreter significantly outperforms the TypeScript implementation!
As this was the main goal of the project, I was very satisfied with these findings.
It had been a journey to get to this point.
However, I knew that by delving deeper into the performance realm, there were plenty more improvements to be made.
I had only really touched upon the low-hanging fruit - with more drastic changes, such as <a href="https://blog.cloudflare.com/building-fast-interpreters-in-rust/#dynamic-dispatch-and-closures-to-the-rescue">compiling to closures</a>, the addition of a JIT, and even implementing a full-blown virtual machine being viable options going forward.</p>

<h2 id="whats-next">What’s Next?</h2>

<p>Now that I have been able to explore and document the performance improvements I could make to the Rust implementation, I want to switch tracks and look at one last important topic - distribution.
In the <a href="https://eddmann.com/posts/rewriting-the-santa-lang-interpreter-in-rust-part-4-distribution/">last post</a> within the <a href="https://eddmann.com/archive/tag/santa-lang-in-rust-series/">series</a>, I will discuss how I built out a CI/CD pipeline to handle packaging and distributing the different runtimes to their relevant targets.
This proved to be an interesting endeavour in itself.</p>

</article>

            </main>

            <footer class="footer">
                <img src="https://www.gravatar.com/avatar/c5c2978bb14d16460f73399c394b6acd?s=160">
                <ul>
                    <li>Developer at <a href="http://www.mybuilder.com/">MyBuilder</a></li>
                    <li><a href="http://threedevsandamaybe.com/">Three Devs and a Maybe</a> podcast co-host</li>
                    <li>All ramblings can be found in the <a href="/archive/">Archive</a></li>
                </ul>
                <div class="cf"></div>
            </footer>
        </div>
    </body>
</html>
