<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance - Edd Mann</title>
<meta name=description content="This blog series details my experience rewriting the santa-lang interpreter in Rust. In this post, I delve into how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way."><meta name=author content="Edd Mann"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPQ7WHNXH4"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZPQ7WHNXH4")}</script><meta itemprop=name content="Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance"><meta itemprop=description content="Now that we have discussed building the core language and desired runtimes, it is time to highlight one of the biggest reasons why I decided to rewrite the interpreter in a lower-level systems language - performance! In this post, I will document how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way."><meta itemprop=datePublished content="2023-08-07T00:00:00+00:00"><meta itemprop=dateModified content="2023-08-07T00:00:00+00:00"><meta itemprop=wordCount content="1234"><meta itemprop=keywords content="Rust,Santa-Lang,Interpreter,Santa-Lang-in-Rust-Series"><meta property="og:url" content="https://eddmann.com/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/"><meta property="og:site_name" content="Edd Mann"><meta property="og:title" content="Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance"><meta property="og:description" content="Now that we have discussed building the core language and desired runtimes, it is time to highlight one of the biggest reasons why I decided to rewrite the interpreter in a lower-level systems language - performance! In this post, I will document how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way."><meta property="og:locale" content="en_GB"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-07T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-07T00:00:00+00:00"><meta property="article:tag" content="Rust"><meta property="article:tag" content="Santa-Lang"><meta property="article:tag" content="Interpreter"><meta property="article:tag" content="Santa-Lang-in-Rust-Series"><meta name=twitter:card content="summary"><meta name=twitter:title content="Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance"><meta name=twitter:description content="Now that we have discussed building the core language and desired runtimes, it is time to highlight one of the biggest reasons why I decided to rewrite the interpreter in a lower-level systems language - performance! In this post, I will document how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way."><meta name=twitter:site content="@edd_mann"><link rel=stylesheet href=/css/style.min.a18bbea58d05187498ffb7d6a33b580609df2e92b988055a4b51e41596cc934e.css integrity="sha256-oYu+pY0FGHSY/7fWoztYBgnfLpK5iAVaS1HkFZbMk04="><link rel=preload as=image href=/assets/x.svg crossorigin=anonymous><link rel=preload as=image href=/assets/github.svg crossorigin=anonymous><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://eddmann.com/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/><script>document.documentElement.setAttribute("data-theme",localStorage.getItem("theme")||window.matchMedia("(prefers-color-scheme: dark)").matches&&"dark"||"light")</script><script src=/script.min.da71ac9c7b8bd4e644618df0ab735aed1393aad3cb5e5c57e5adc300fe7c8209.js integrity="sha256-2nGsnHuL1OZEYY3wq3Na7ROTqtPLXlxX5a3DAP58ggk=" defer></script></head><body><header class="site-header l-wrapper"><a href=https://eddmann.com/><h3 class=site-header__title>Edd Mann
<span style=--url:url(/assets/code.svg)>Developer</span></h3></a><button class=site-header__mobile-navigation-button type=button title="Toggle mobile site navigation" aria-label="Toggle mobile site navigation" aria-expanded=false aria-controls=site-navigation></button><div class=site-header__navigation id=site-navigation><nav aria-label="Primary navigation"><ul class=site-header__primary-navigation><li><a href=/archive>Archive</a></li><li><a href=/projects>Projects</a></li><li><a href=/about>About</a></li></ul></nav><nav aria-label="Social links"><ul class=site-header__social-navigation><li><a class=social-icon style=--url:url(/assets/x.svg) href=https://x.com/edd_mann rel="external noopener" target=_blank>Twitter (X)</a></li><li><a class=social-icon style=--url:url(/assets/github.svg) href=https://github.com/eddmann rel="external noopener" target=_blank>GitHub</a></li></ul></nav></div></header><main class=l-wrapper><article><header class=l-page-title><h1 class=u-transition-between-pages style=--id:rewriting-the-santa-lang-interpreter-in-rust-part-3-performance>Rewriting the santa-lang Interpreter in Rust, Part 3 - Performance</h1><time datetime=2023-08-07T00:00:00Z class=published-at>Aug 7, 2023</time></header><main class=u-prose><p>Now that we have discussed building the core language and desired runtimes, it is time to highlight one of the biggest reasons why I decided to rewrite the interpreter in a lower-level systems language - performance!
In this post, I will document how I went about benchmarking the two implementations (TypeScript/Node and Rust), greatly improving performance and highlighting interesting findings along the way.</p><p>All benchmarks require a stable base, and as such, I decided to concentrate my efforts on the CLI runtimes.
This runtime is the one I use the most whilst developing Advent of Code solutions over the course of December.</p><h2 id=sizing-it-up>Sizing It Up&mldr;</h2><p>The first point that struck me was how much smaller the Rust binary artifact was - 3.8MB vs 47MB.
This is a bit of an unfair comparison as the TypeScript version is required to package up the entire <a href=https://www.npmjs.com/package/pkg rel="external noopener" target=_blank>Node runtime</a> in order to be self-executable.
However, it did show how much smaller the same behaviour could be modelled in.
I was able to reduce the Rust binary size further using several <a href=https://nnethercote.github.io/perf-book/build-configuration.html rel="external noopener" target=_blank>build configuration options</a>: <code>strip</code>, <code>codegen-units</code>, <code>lto</code>.</p><h2 id=initial-benchmarks>Initial Benchmarks</h2><p>Thanks to solving the <a href=/posts/solving-the-advent-of-code-2022-calendar-using-my-own-programming-language-santa-lang/>Advent of Code 2022</a> calendar in santa-lang, I had a good suite of examples for benchmarking the two variants.
Coupled with this, I included some simple examples which documented common language constructs that were present within the language, i.e., arithmetic, recursion, and looping.
One such example used recursion to compute the <em>nth</em> term in the Fibonacci sequence:</p><pre tabindex=0><code>let fibonacci = |n| if n &lt; 2 { n } else { fibonacci(n - 1) + fibonacci(n - 2) };
fibonacci(20);
</code></pre><p>Another example included a large arithmetic operation to test how the interpreter coped with parsing and evaluating such an expression.
I also included an example which was an empty file to baseline the interpreter&rsquo;s fixed overheads.
To provide reliable benchmark results for these examples, I used <a href=https://github.com/sharkdp/hyperfine rel="external noopener" target=_blank>hyperfine</a> with the following configuration:</p><pre tabindex=0><code>hyperfine
    -n ts &#34;./santa-cli-ts fibonacci.santa&#34;
    -n rs &#34;./santa-cli-rs fibonacci.santa&#34;
    --time-unit millisecond
    --warmup 3
    --export-json fibonacci.json
    --runs 10
</code></pre><p>With this framework in place, I went on to perform my initial round of benchmarks on the two variants and was shocked by the results.
Several Rust example executions resulted in expected significant performance gains compared to the Node variant, thanks in large part to the quicker initialisation times and lighter-weight evaluator <code>Object</code> model.
However, there were many cases where the Node variant outperformed the Rust version - and not by small margins?!</p><h2 id=lets-get-profiling>Let&rsquo;s Get Profiling</h2><p>It was at this time that I delved deeper into the Rust implementation, instrumenting my <a href=https://github.com/tikv/pprof-rs rel="external noopener" target=_blank>code</a> to profile how much time was spent at each step.
I additionally spent some time adding the ability to produce <a href=https://www.brendangregg.com/flamegraphs.html rel="external noopener" target=_blank>flame graphs</a>, which allow you to clearly visualise the profile output:</p><p><picture><source type=image/webp srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_ecf866d22ab4947a.webp 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_47294435024cb290.webp 700w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_97570c78674c7cb0.webp 1400w"><source type=image/jpeg srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_4f6fcc7405281b26.jpg 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_afdcec64ae02e2ed.jpg 700w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_b49ad77c6257570d.jpg 1400w"><img src=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/flamegraph_hu_afdcec64ae02e2ed.jpg alt="Flame graph" loading=lazy></picture></p><h3 id=infix-operators>Infix Operators</h3><p>Looking at these initial flame graphs led me to several changes in how infix operators were executed.
As the language supports the use of these operators within infix position as well as by function call, I had provided this functionality by way of shared Rust built-in function definitions.
This incurred a function invocation per infix operator, so instead, I opted to <a href=https://nnethercote.github.io/perf-book/inlining.html rel="external noopener" target=_blank>inline</a> these functions.
Paying attention to not being hit by CPU cache performance penalties, I noticed the needless function stack allocations disappear.
Although this did help with performance, it still was not the boost that I had been hoping for, so the journey continued&mldr;</p><h3 id=environment-variables>Environment Variables</h3><p>The next step I took was to replace the <a href=https://nnethercote.github.io/perf-book/hashing.html rel="external noopener" target=_blank>hash map implementation</a> I used within the environment that holds scoped variables.
I had noticed that time was spent resolving these environment variables, so I explored replacing the inbuilt hash map with a quicker (although less cryptographically secure) alternative, <a href=https://github.com/cbreeden/fxhash rel="external noopener" target=_blank>FxHashMap</a>.
This again did not reap the rewards that I had been hoping for, and instead, thanks to a <a href=https://www.dannyvankooten.com/blog/2022/rewriting-interpreter-rust/ rel="external noopener" target=_blank>very interesting post</a>, I opted to use a vector to represent the environment variables.
This provided quicker variable resolution, whereby it was, interestingly, more performant to traverse a sequential list in memory than apply a hash and resolve the variable from a determined <em>bucket</em>.
This performance improvement was based on the code heuristic that there would be a limited number of variables per scope.
Sadly, after additional benchmarking, this chipped away some execution time, but I was still not satisfied.</p><h3 id=memory-allocation>Memory Allocation</h3><p>I thought I needed to take a different approach and turned my attention to the Node variant.
One train of thought I had was that maybe the Node&rsquo;s performance was better for some use cases due to the included just-in-time compiler (JIT), with &lsquo;hot paths&rsquo; being compiled to native code.
To check this, I explored <a href=https://v8.dev/blog/jitless rel="external noopener" target=_blank>disabling the Node JIT</a> and was amazed at how much less performant it was.
Perhaps this was as far as I could go with a simple tree-walking interpreter&mldr;</p><p>All my benchmarks to date had been performed on macOS, and to garner additional insights into my performance woes, I decided to use a Linux tool, <a href=https://perf.wiki.kernel.org/index.php/Main_Page rel="external noopener" target=_blank>perf</a>.
What surprised me when I ran the examples on Linux was how much more performant they were - they were blowing the performance of the Node variant out of the water!?
After closer inspection, I pinpointed that this was due to the different default memory heap allocators used in the two operating systems.
Linux was using <a href=https://jemalloc.net/ rel="external noopener" target=_blank>jemalloc</a>, touted for reducing memory fragmentation, which is invaluable when performing many small memory heap allocations like santa-lang does.
Due to this finding, I changed the <a href=https://crates.io/crates/tikv-jemallocator rel="external noopener" target=_blank>default Rust allocator</a> and was able to see a comparable performance increase when executing the solutions on macOS!</p><p>I felt like this was a good place to stop tuning the interpreter for performance at this time and enjoy the performance improvements that I had managed to achieve to date.</p><h2 id=final-benchmarks>Final Benchmarks</h2><p>With all the performance tuning out of the way (for the time being), it was time to see how much more performant the Rust variant was compared to its TypeScript compatriot.
Below is a graph (created using <a href=https://matplotlib.org/ rel="external noopener" target=_blank>Matplotlib</a>) benchmarking the example scripts I used to model typical language feature usage:</p><p><picture><source type=image/webp srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/standard-benchmark_hu_21ee431d2ec91b97.webp 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/standard-benchmark_hu_19bf34824386d3cb.webp 640w"><source type=image/jpeg srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/standard-benchmark_hu_80ac90b66082cd1e.jpg 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/standard-benchmark_hu_117c0e2608e3f100.jpg 640w"><img src=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/standard-benchmark_hu_117c0e2608e3f100.jpg alt="Standard Benchmark" loading=lazy></picture></p><p>Visualising the benchmarks for the Advent of Code solutions proved to be a bit trickier due to some solutions being orders of magnitude slower than others.
As such, I broke these findings into two graphs, the first using milliseconds as the unit of measurement:</p><p><picture><source type=image/webp srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_d6265a8227ff2b5f.webp 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_5edd4f0d7187603c.webp 700w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_12f660b7a2f81c57.webp 1315w"><source type=image/jpeg srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_336447ed97a01793.jpg 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_59004cd4e6f7c5a3.jpg 700w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_7e80de8f1e3dc34.jpg 1315w"><img src=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-1_hu_59004cd4e6f7c5a3.jpg alt="Advent of Code 2022 Benchmark 1" loading=lazy></picture></p><p>And the second graph using seconds as the unit of measurement:</p><p><picture><source type=image/webp srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-2_hu_f3da3f097d628b2d.webp 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-2_hu_a2b7f660a0a08232.webp 675w"><source type=image/jpeg srcset="/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-2_hu_93399c3c72a88d15.jpg 350w, /posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-2_hu_146ce5a0c9d8a9e4.jpg 675w"><img src=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-3-performance/aoc-2022-benchmark-2_hu_146ce5a0c9d8a9e4.jpg alt="Advent of Code 2022 Benchmark 2" loading=lazy></picture></p><p>As you can see, in all cases, the Rust interpreter significantly outperforms the TypeScript implementation!
As this was the main goal of the project, I was very satisfied with these findings.
It had been a journey to get to this point.
However, I knew that by delving deeper into the performance realm, there were plenty more improvements to be made.
I had only really touched upon the low-hanging fruit - with more drastic changes, such as <a href=https://blog.cloudflare.com/building-fast-interpreters-in-rust/#dynamic-dispatch-and-closures-to-the-rescue rel="external noopener" target=_blank>compiling to closures</a>, the addition of a JIT, and even implementing a full-blown virtual machine being viable options going forward.</p><h2 id=whats-next>What&rsquo;s Next?</h2><p>Now that I have been able to explore and document the performance improvements I could make to the Rust implementation, I want to switch tracks and look at one last important topic - distribution.
In the <a href=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-4-distribution/>last post</a> within the <a href=/archive/tag/santa-lang-in-rust-series>series</a>, I will discuss how I built out a CI/CD pipeline to handle packaging and distributing the different runtimes to their relevant targets.
This proved to be an interesting endeavour in itself.</p></main><footer class=post-footer><ul class="tags tags--large"><li><a href=/archive/tag/rust>rust</a></li><li><a href=/archive/tag/santa-lang>santa-lang</a></li><li><a href=/archive/tag/interpreter>interpreter</a></li><li><a href=/archive/tag/santa-lang-in-rust-series>santa-lang-in-rust-series</a></li></ul><div class=related><h3 class=related__title>Related Posts</h3><ul class=related__posts><li><a href=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-2-runtimes/>Rewriting the santa-lang Interpreter in Rust, Part 2 - Runtimes</a></li><li><a href=/posts/rewriting-the-santa-lang-interpreter-in-rust-part-1-implementing-the-core/>Rewriting the santa-lang Interpreter in Rust, Part 1 - Implementing the Core</a></li><li><a href=/posts/solving-the-advent-of-code-2022-calendar-using-my-own-programming-language-santa-lang/>Solving the Advent of Code 2022 calendar using my own programming language, santa-lang</a></li><li><a href=/posts/designing-santa-lang-a-language-for-solving-advent-of-code-puzzles/>Designing santa-lang, a language for solving Advent of Code puzzles</a></li><li><a href=/posts/allocating-secret-santas-using-an-aws-step-function-workflow-and-every-available-lambda-runtime/>Allocating Secret Santas using an AWS Step Function workflow and every available Lambda runtime</a></li></ul></div></footer></article><div class=scroll-watcher></div></main><footer class="site-footer l-wrapper"><div>&copy; 2025, Edd Mann</div><button class=site-footer__theme-toggle type=button title="Toggle theme" aria-label="Toggle theme"><svg fill="currentcolor" viewBox="0 0 32 32" role="img"><title>Theme toggle icon</title><desc>A circle representing the moon for toggling theme</desc><path d="M16 .5C7.4.5.5 7.4.5 16S7.4 31.5 16 31.5 31.5 24.6 31.5 16 24.6.5 16 .5zm0 28.1V3.4C23 3.4 28.6 9 28.6 16S23 28.6 16 28.6z"/></svg></button></footer></body></html>