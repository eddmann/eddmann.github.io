<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Q&amp;A Retrieval Augmented Generation (RAG) with LangChain and Chroma - Edd Mann</title>
<meta name=description content="This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and the Chroma vector database."><meta name=author content="Edd Mann"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPQ7WHNXH4"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZPQ7WHNXH4")}</script><meta itemprop=name content="Q&A Retrieval Augmented Generation (RAG) with LangChain and Chroma"><meta itemprop=description content="Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment. Like many developers, I am interested in exploring what is possible with this new technology. This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and the Chroma vector database."><meta itemprop=datePublished content="2023-05-10T00:00:00+00:00"><meta itemprop=dateModified content="2023-05-10T00:00:00+00:00"><meta itemprop=wordCount content="1412"><meta itemprop=keywords content="Llm,Langchain,Chromadb"><meta property="og:url" content="https://eddmann.com/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/"><meta property="og:site_name" content="Edd Mann"><meta property="og:title" content="Q&A Retrieval Augmented Generation (RAG) with LangChain and Chroma"><meta property="og:description" content="Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment. Like many developers, I am interested in exploring what is possible with this new technology. This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and the Chroma vector database."><meta property="og:locale" content="en_GB"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-10T00:00:00+00:00"><meta property="article:modified_time" content="2023-05-10T00:00:00+00:00"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Chromadb"><meta name=twitter:card content="summary"><meta name=twitter:title content="Q&A Retrieval Augmented Generation (RAG) with LangChain and Chroma"><meta name=twitter:description content="Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment. Like many developers, I am interested in exploring what is possible with this new technology. This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and the Chroma vector database."><meta name=twitter:site content="@edd_mann"><link rel=stylesheet href=/css/style.min.3182afb340a83ee2b29f9b972282f896d25ab9c363ef5462a251fa004875db3e.css integrity="sha256-MYKvs0CoPuKyn5uXIoL4ltJaucNj71RiolH6AEh12z4="><link rel=preload as=image href=/assets/x.svg><link rel=preload as=image href=/assets/github.svg><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://eddmann.com/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/><script>(function(){document.documentElement.setAttribute("data-theme",localStorage.getItem("theme")||window.matchMedia("(prefers-color-scheme: dark)").matches&&"dark"||"light")})()</script><script src=/script.min.7b3001f959164202b0ed43cdde230bfa9d8f579831cc5e4f9853519364eb2fbe.js integrity="sha256-ezAB+VkWQgKw7UPN3iML+p2PV5gxzF5PmFNRk2TrL74=" defer></script></head><body><header class="site-header l-wrapper"><a href=https://eddmann.com/><h3 class=site-header__title>Edd Mann
<span style=--url:url(/assets/code.svg)>Developer</span></h3></a><button class=site-header__mobile-navigation-button type=button title="Toggle mobile site navigation" aria-label="Toggle mobile site navigation" aria-expanded=false aria-controls=site-navigation></button><div class=site-header__navigation id=site-navigation><nav aria-label="Primary navigation"><ul class=site-header__primary-navigation><li><a href=/archive>Archive</a></li><li><a href=/projects>Projects</a></li><li><a href=/about>About</a></li></ul></nav><nav aria-label="Social links"><ul class=site-header__social-navigation><li><a class=social-icon style=--url:url(/assets/x.svg) href=https://x.com/edd_mann rel="external noopener" target=_blank>Twitter (X)</a></li><li><a class=social-icon style=--url:url(/assets/github.svg) href=https://github.com/eddmann rel="external noopener" target=_blank>GitHub</a></li></ul></nav></div></header><main class=l-wrapper><article><header class=l-page-title><h1 class=u-transition-between-pages style=--id:qa-retrieval-augmented-generation-rag-with-langchain-and-chroma>Q&amp;A Retrieval Augmented Generation (RAG) with LangChain and Chroma</h1><time datetime=2023-05-10T00:00:00Z class=post__time>May 10, 2023</time></header><main class=u-prose><p>Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment.
Like many developers, I am interested in exploring what is possible with this new technology.
This post documents my experience exploring how to implement <a href=https://python.langchain.com/docs/use_cases/question_answering/ rel="external noopener" target=_blank>Q&amp;A Retrieval Augmented Generation</a> (RAG) using LangChain and the <a href=https://www.trychroma.com/ rel="external noopener" target=_blank>Chroma</a> vector database.</p><p>This post was originally written as a Jupyter Notebook, which can be <a href=/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/qa-retrieval-with-chroma.ipynb>downloaded here</a>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>pip install langchain openai datasets chromadb
</span></span></code></pre></div><h2 id=loading-a-dataset-into-chroma>Loading a Dataset into Chroma</h2><p>We will initially load a dataset (Wikipedia article corpus) and chunk it into input that we can feed into the vector database.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> datasets <span style=color:#f92672>import</span> load_dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#34;wikipedia&#34;</span>, <span style=color:#e6db74>&#34;20220301.simple&#34;</span>, split<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;train[:10]&#39;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.text_splitter <span style=color:#f92672>import</span> RecursiveCharacterTextSplitter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>text_splitter <span style=color:#f92672>=</span> RecursiveCharacterTextSplitter(
</span></span><span style=display:flex><span>    chunk_size<span style=color:#f92672>=</span><span style=color:#ae81ff>400</span>,
</span></span><span style=display:flex><span>    chunk_overlap<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>text_splitter<span style=color:#f92672>.</span>split_text(data[<span style=color:#ae81ff>6</span>][<span style=color:#e6db74>&#39;text&#39;</span>])[:<span style=color:#ae81ff>3</span>]
</span></span></code></pre></div><pre tabindex=0><code>[&#39;Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n\nEarly life and family \nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.&#39;,
 &#39;Education \nTuring went to St. Michael\&#39;s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n&#34;This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.&#39;,
 &#39;The Stoney family were once prominent landlords, here in North Tipperary. His mother Ethel Sara Stoney (1881–1976) was daughter of Edward Waller Stoney (Borrisokane, North Tipperary) and Sarah Crawford (Cartron Abbey, Co. Longford); Protestant Anglo-Irish gentry.&#39;]
</code></pre><p>We can now generate embeddings of each dataset chunk and store these within the Chroma vector database.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.docstore.document <span style=color:#f92672>import</span> Document
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.vectorstores <span style=color:#f92672>import</span> Chroma
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.embeddings.openai <span style=color:#f92672>import</span> OpenAIEmbeddings
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>embeddings <span style=color:#f92672>=</span> OpenAIEmbeddings(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;text-embedding-ada-002&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>documents <span style=color:#f92672>=</span> \
</span></span><span style=display:flex><span>    [Document(page_content<span style=color:#f92672>=</span>chunk_text, metadata<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;id&#34;</span>: record[<span style=color:#e6db74>&#39;id&#39;</span>] <span style=color:#f92672>+</span> str(chunk_idx), <span style=color:#e6db74>&#34;source&#34;</span>: record[<span style=color:#e6db74>&#39;url&#39;</span>]})
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>for</span> record <span style=color:#f92672>in</span> data
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>for</span> (chunk_idx, chunk_text) <span style=color:#f92672>in</span> enumerate(text_splitter<span style=color:#f92672>.</span>split_text(record[<span style=color:#e6db74>&#39;text&#39;</span>]))]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>store <span style=color:#f92672>=</span> Chroma<span style=color:#f92672>.</span>from_documents(documents, embeddings)
</span></span></code></pre></div><p>We can then search the vector database for the given articles that have the most relevance to the given query.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>query <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;Where was Alan Turing born and what is an Enigma machine?&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>store<span style=color:#f92672>.</span>similarity_search(query)
</span></span></code></pre></div><pre tabindex=0><code>[Document(page_content=&#39;Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n\nEarly life and family \nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.&#39;, metadata={&#39;id&#39;: &#39;130&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
 Document(page_content=&#39;Educated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.&#39;, metadata={&#39;id&#39;: &#39;133&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
 Document(page_content=&#39;A brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the&#39;, metadata={&#39;id&#39;: &#39;134&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
 Document(page_content=&#39;Education \nTuring went to St. Michael\&#39;s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n&#34;This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.&#39;, metadata={&#39;id&#39;: &#39;131&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;})]
</code></pre><h2 id=integrating-the-data-source-with-an-llm>Integrating the Data Source with an LLM</h2><p>Now we can wire up the LLM to use the Chroma vector database within a <code>RetrievalQA</code> chain.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chat_models <span style=color:#f92672>import</span> ChatOpenAI
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>llm <span style=color:#f92672>=</span> ChatOpenAI(
</span></span><span style=display:flex><span>    model_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gpt-3.5-turbo&#39;</span>,
</span></span><span style=display:flex><span>    temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>There are several different ways we can compile and ask the LLM the question.</p><h3 id=stuff>Stuff</h3><blockquote><p>The stuff documents chain (&ldquo;stuff&rdquo; as in &ldquo;to stuff&rdquo; or &ldquo;to fill&rdquo;) is the most straightforward of the document chains.
It takes a list of documents, inserts them all into a prompt and passes that prompt to an LLM.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> RetrievalQA
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> RetrievalQA<span style=color:#f92672>.</span>from_chain_type(
</span></span><span style=display:flex><span>    llm<span style=color:#f92672>=</span>llm,
</span></span><span style=display:flex><span>    chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stuff&#34;</span>,
</span></span><span style=display:flex><span>    retriever<span style=color:#f92672>=</span>store<span style=color:#f92672>.</span>as_retriever()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa<span style=color:#f92672>.</span>run(query)
</span></span></code></pre></div><blockquote><p>Alan Turing was born in Maida Vale, London.
An Enigma machine was a cipher machine used by the Nazi German military during World War II to encrypt and decrypt secret messages. It was considered highly secure at the time and was used to protect sensitive communications.
Turing played a crucial role in breaking the Enigma code, which greatly aided the Allied forces in their efforts during the war.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> RetrievalQAWithSourcesChain
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa_with_sources <span style=color:#f92672>=</span> RetrievalQAWithSourcesChain<span style=color:#f92672>.</span>from_chain_type(
</span></span><span style=display:flex><span>    llm<span style=color:#f92672>=</span>llm,
</span></span><span style=display:flex><span>    chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stuff&#34;</span>,
</span></span><span style=display:flex><span>    retriever<span style=color:#f92672>=</span>store<span style=color:#f92672>.</span>as_retriever()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa_with_sources(query)
</span></span></code></pre></div><pre tabindex=0><code>{&#39;question&#39;: &#39;Where was Alan Turing born and what is an Engima machine?&#39;,
 &#39;answer&#39;: &#39;Alan Turing was born in Maida Vale, London. An Enigma machine was a device designed by Turing at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine during World War 2.\n&#39;,
 &#39;sources&#39;: &#39;\n- https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}
</code></pre><h3 id=map-reduce>Map-Reduce</h3><blockquote><p>The map reduce documents chain first applies an LLM chain to each document individually (the Map step), treating the chain output as a new document.
It then passes all the new documents to a separate combine documents chain to get a single output (the Reduce step).</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains.question_answering <span style=color:#f92672>import</span> load_qa_chain
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> RetrievalQA(
</span></span><span style=display:flex><span>    combine_documents_chain<span style=color:#f92672>=</span>load_qa_chain(llm, chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;map_reduce&#34;</span>),
</span></span><span style=display:flex><span>    retriever<span style=color:#f92672>=</span>store<span style=color:#f92672>.</span>as_retriever()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa<span style=color:#f92672>.</span>run(query)
</span></span></code></pre></div><blockquote><p>The given portion of the document does not provide any information about where Alan Turing was born or what an Enigma machine is.</p></blockquote><p>Unfortunately, this type of chain does not appear to return the desired results.</p><h2 id=building-a-qa-chatbot>Building a Q&amp;A Chatbot</h2><p>We can also use the <code>ConversationalRetrievalChain</code> to build a chatbot that we can interact with to answer the desired questions.
This includes adding <em>memory</em>, which allows us to ask follow-up questions based on previous conversations.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> ConversationalRetrievalChain
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.memory <span style=color:#f92672>import</span> ConversationBufferMemory
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>memory <span style=color:#f92672>=</span> ConversationBufferMemory(memory_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chat_history&#34;</span>, return_messages<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> ConversationalRetrievalChain<span style=color:#f92672>.</span>from_llm(llm, store<span style=color:#f92672>.</span>as_retriever(), memory<span style=color:#f92672>=</span>memory)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa({<span style=color:#e6db74>&#34;question&#34;</span>: <span style=color:#e6db74>&#34;Where was Alan Turing born?&#34;</span>})
</span></span><span style=display:flex><span>qa({<span style=color:#e6db74>&#34;question&#34;</span>: <span style=color:#e6db74>&#34;What year was he born?&#34;</span>})
</span></span></code></pre></div><pre tabindex=0><code>{&#39;question&#39;: &#39;What year was he born?&#39;,
 &#39;chat_history&#39;: [HumanMessage(content=&#39;Where was Alan Turing born?&#39;, additional_kwargs={}, example=False),
  AIMessage(content=&#39;Alan Turing was born in Maida Vale, London.&#39;, additional_kwargs={}, example=False),
  HumanMessage(content=&#39;What year was he born?&#39;, additional_kwargs={}, example=False),
  AIMessage(content=&#39;Alan Turing was born in 1912.&#39;, additional_kwargs={}, example=False)],
 &#39;answer&#39;: &#39;Alan Turing was born in 1912.&#39;}
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>qa <span style=color:#f92672>=</span> ConversationalRetrievalChain<span style=color:#f92672>.</span>from_llm(llm, store<span style=color:#f92672>.</span>as_retriever(), return_source_documents<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa({<span style=color:#e6db74>&#34;question&#34;</span>: query, <span style=color:#e6db74>&#34;chat_history&#34;</span>: []})
</span></span></code></pre></div><pre tabindex=0><code>{&#39;question&#39;: &#39;Where was Alan Turing born and what is an Engima machine?&#39;,
 &#39;chat_history&#39;: [],
 &#39;answer&#39;: &#39;Alan Turing was born in Maida Vale, London. \n\nAn Enigma machine was a cipher machine used by the Nazi German military during World War II to encrypt and decrypt secret messages. It was considered highly secure at the time and was used to protect sensitive communications. Turing played a crucial role in breaking the Enigma code, which greatly aided the Allied forces in their efforts during the war.&#39;,
 &#39;source_documents&#39;: [Document(page_content=&#39;Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n\nEarly life and family \nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.&#39;, metadata={&#39;id&#39;: &#39;130&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
  Document(page_content=&#39;Educated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.&#39;, metadata={&#39;id&#39;: &#39;133&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
  Document(page_content=&#39;A brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the&#39;, metadata={&#39;id&#39;: &#39;134&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
  Document(page_content=&#39;Education \nTuring went to St. Michael\&#39;s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n&#34;This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.&#39;, metadata={&#39;id&#39;: &#39;131&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;})]}
</code></pre><h3 id=adding-a-ui>Adding a UI</h3><p>Thanks to <a href=https://www.gradio.app/ rel="external noopener" target=_blank>Gradio</a>, we can front this chain with a simple chat UI.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>pip install gradio
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> gradio <span style=color:#66d9ef>as</span> gr
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>memory <span style=color:#f92672>=</span> ConversationBufferMemory(memory_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chat_history&#34;</span>, return_messages<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> ConversationalRetrievalChain<span style=color:#f92672>.</span>from_llm(llm, store<span style=color:#f92672>.</span>as_retriever(), memory<span style=color:#f92672>=</span>memory)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> gr<span style=color:#f92672>.</span>Blocks() <span style=color:#66d9ef>as</span> demo:
</span></span><span style=display:flex><span>    chatbot <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Chatbot()
</span></span><span style=display:flex><span>    msg <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Textbox()
</span></span><span style=display:flex><span>    clear <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>ClearButton([msg, chatbot])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>respond</span>(message, chat_history):
</span></span><span style=display:flex><span>        result <span style=color:#f92672>=</span> qa({<span style=color:#e6db74>&#34;question&#34;</span>: message})
</span></span><span style=display:flex><span>        chat_history<span style=color:#f92672>.</span>append((message, result[<span style=color:#e6db74>&#39;answer&#39;</span>]))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;&#34;</span>, chat_history
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    msg<span style=color:#f92672>.</span>submit(respond, [msg, chatbot], [msg, chatbot])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>demo<span style=color:#f92672>.</span>launch()
</span></span></code></pre></div><p><picture><source type=image/webp srcset="/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_79702d60d05aa9a8.webp 350w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_55ba6e30d1643256.webp 700w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_15b2755ed4a1cbb9.webp 1258w"><source type=image/jpeg srcset="/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_5e3d227718e85c3a.jpg 350w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_31bb496b05b046c8.jpg 700w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_de60e2e22b5ffa18.jpg 1258w"><img src=/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/chatbot_hu_31bb496b05b046c8.jpg alt=Chatbot loading=lazy></picture></p></main><footer class=post__tags><a href=/archive/tag/llm>llm</a><a href=/archive/tag/langchain>langchain</a><a href=/archive/tag/chromadb>chromadb</a></footer></article><div class=scroll-watcher></div></main><footer class="site-footer l-wrapper"><div>&copy; 2025, Edd Mann</div><button class=site-footer__theme-toggle type=button title="Toggle theme" aria-label="Toggle theme"><svg fill="currentcolor" viewBox="0 0 32 32" role="img"><title>Theme toggle icon</title><desc>A circle representing the moon for toggling theme</desc><path d="M16 .5C7.4.5.5 7.4.5 16S7.4 31.5 16 31.5 31.5 24.6 31.5 16 24.6.5 16 .5zm0 28.1V3.4C23 3.4 28.6 9 28.6 16S23 28.6 16 28.6z"/></svg></button></footer></body></html>