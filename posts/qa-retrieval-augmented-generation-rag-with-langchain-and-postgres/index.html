<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Q&amp;A Retrieval Augmented Generation (RAG) with LangChain and Postgres - Edd Mann</title>
<meta name=description content="Explore how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and Postgres with the pgvector extension, leveraging LLMs for intelligent document querying."><meta name=author content="Edd Mann"><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZPQ7WHNXH4"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZPQ7WHNXH4")}</script><meta itemprop=name content="Q&A Retrieval Augmented Generation (RAG) with LangChain and Postgres"><meta itemprop=description content="Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment. Like many developers, I am interested in exploring what is possible with this new technology. This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and Postgres (using the pgvector extension)."><meta itemprop=datePublished content="2023-05-15T00:00:00+00:00"><meta itemprop=dateModified content="2023-05-15T00:00:00+00:00"><meta itemprop=wordCount content="1477"><meta itemprop=keywords content="Llm,Langchain,Postgres"><meta property="og:url" content="https://eddmann.com/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/"><meta property="og:site_name" content="Edd Mann"><meta property="og:title" content="Q&A Retrieval Augmented Generation (RAG) with LangChain and Postgres"><meta property="og:description" content="Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment. Like many developers, I am interested in exploring what is possible with this new technology. This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and Postgres (using the pgvector extension)."><meta property="og:locale" content="en_GB"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-15T00:00:00+00:00"><meta property="article:modified_time" content="2023-05-15T00:00:00+00:00"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Langchain"><meta property="article:tag" content="Postgres"><meta name=twitter:card content="summary"><meta name=twitter:title content="Q&A Retrieval Augmented Generation (RAG) with LangChain and Postgres"><meta name=twitter:description content="Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment. Like many developers, I am interested in exploring what is possible with this new technology. This post documents my experience exploring how to implement Q&amp;A Retrieval Augmented Generation (RAG) using LangChain and Postgres (using the pgvector extension)."><meta name=twitter:site content="@edd_mann"><link rel="preload stylesheet" as=style href=/css/style.min.6b5d0ef6e3fcc342a7b1bb186a93637ef078dec14a4a0fe2665258ada27fdc79.css integrity="sha256-a10O9uP8w0KnsbsYapNjfvB43sFKSg/iZlJYraJ/3Hk="><link rel=preload as=image href=/assets/x.svg><link rel=preload as=image href=/assets/github.svg><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://eddmann.com/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/></head><body><header class="site-header wrapper"><a href=https://eddmann.com/><h3 class=site-header__title>Edd Mann
<span style=--url:url(/assets/code.svg)>Developer</span></h3></a><div class=site-header__mobile-navigation-button aria-label="Toggle mobile site navigation" aria-expanded=false aria-controls=site-navigation></div><div class=site-header__navigation id=site-navigation><nav aria-label="Primary navigation"><ul class=site-header__primary-navigation><li><a href=/archive>Archive</a></li><li><a href=/projects>Projects</a></li><li><a href=/about>About</a></li></ul></nav><nav aria-label="Social links"><ul class=site-header__social-navigation><li><a class=social-icon style=--url:url(/assets/x.svg) href=https://x.com/edd_mann rel="external noopener" target=_blank>Twitter (X)</a></li><li><a class=social-icon style=--url:url(/assets/github.svg) href=https://github.com/eddmann rel="external noopener" target=_blank>GitHub</a></li></ul></nav></div></header><main class=wrapper><article><header class=page-title><h1 class=transition-between-pages style=--id:qa-retrieval-augmented-generation-rag-with-langchain-and-postgres>Q&amp;A Retrieval Augmented Generation (RAG) with LangChain and Postgres</h1><time class=post__time>May 15, 2023</time></header><main class=prose><p>Large-language models (OpenAI/ChatGPT in particular) are all the rage at the moment.
Like many developers, I am interested in exploring what is possible with this new technology.
This post documents my experience exploring how to implement <a href=https://python.langchain.com/docs/use_cases/question_answering/ rel="external noopener" target=_blank>Q&amp;A Retrieval Augmented Generation</a> (RAG) using LangChain and Postgres (using the <a href=https://github.com/pgvector/pgvector rel="external noopener" target=_blank>pgvector</a> extension).</p><p>This post was originally written as a Jupyter Notebook, which can be <a href=/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/qa-retrieval-with-pgvector.ipynb>downloaded here</a>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>pip install langchain openai datasets pgvector psycopg2<span style=color:#f92672>-</span>binary
</span></span></code></pre></div><h2 id=loading-a-dataset-into-postgres>Loading a Dataset into Postgres</h2><p>We will initially load a dataset (Wikipedia article corpus) and chunk it into input that we can feed into the vector database.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> datasets <span style=color:#f92672>import</span> load_dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> load_dataset(<span style=color:#e6db74>&#34;wikipedia&#34;</span>, <span style=color:#e6db74>&#34;20220301.simple&#34;</span>, split<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;train[:10]&#39;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.text_splitter <span style=color:#f92672>import</span> RecursiveCharacterTextSplitter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>text_splitter <span style=color:#f92672>=</span> RecursiveCharacterTextSplitter(
</span></span><span style=display:flex><span>    chunk_size<span style=color:#f92672>=</span><span style=color:#ae81ff>400</span>,
</span></span><span style=display:flex><span>    chunk_overlap<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>text_splitter<span style=color:#f92672>.</span>split_text(data[<span style=color:#ae81ff>6</span>][<span style=color:#e6db74>&#39;text&#39;</span>])[:<span style=color:#ae81ff>3</span>]
</span></span></code></pre></div><pre tabindex=0><code>[&#39;Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n\nEarly life and family \nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.&#39;,
 &#39;Education \nTuring went to St. Michael\&#39;s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n&#34;This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.&#39;,
 &#39;The Stoney family were once prominent landlords, here in North Tipperary. His mother Ethel Sara Stoney (1881–1976) was daughter of Edward Waller Stoney (Borrisokane, North Tipperary) and Sarah Crawford (Cartron Abbey, Co. Longford); Protestant Anglo-Irish gentry.&#39;]
</code></pre><p>We can now generate embeddings of each dataset chunk and store these within Postgres.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.docstore.document <span style=color:#f92672>import</span> Document
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>documents <span style=color:#f92672>=</span> \
</span></span><span style=display:flex><span>    [Document(page_content<span style=color:#f92672>=</span>chunk_text, metadata<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#34;id&#34;</span>: record[<span style=color:#e6db74>&#39;id&#39;</span>] <span style=color:#f92672>+</span> str(chunk_idx), <span style=color:#e6db74>&#34;source&#34;</span>: record[<span style=color:#e6db74>&#39;url&#39;</span>]})
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>for</span> record <span style=color:#f92672>in</span> data
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>for</span> (chunk_idx, chunk_text) <span style=color:#f92672>in</span> enumerate(text_splitter<span style=color:#f92672>.</span>split_text(record[<span style=color:#e6db74>&#39;text&#39;</span>]))]
</span></span></code></pre></div><p>Next, we can start a local Postgres instance with the <code>pgvector</code> extension present.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>docker run --rm -it <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --name vector-store <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -p 5432:5432 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -e POSTGRES_USER<span style=color:#f92672>=</span>postgres <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -e POSTGRES_PASSWORD<span style=color:#f92672>=</span>postgres <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  -e POSTGRES_DB<span style=color:#f92672>=</span>postgres <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  ankane/pgvector -c log_statement<span style=color:#f92672>=</span>all
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.vectorstores.pgvector <span style=color:#f92672>import</span> PGVector
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> sqlalchemy
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>connection_string <span style=color:#f92672>=</span> PGVector<span style=color:#f92672>.</span>connection_string_from_db_params(
</span></span><span style=display:flex><span>    driver<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;psycopg2&#34;</span>,
</span></span><span style=display:flex><span>    host<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;0.0.0.0&#34;</span>,
</span></span><span style=display:flex><span>    port<span style=color:#f92672>=</span><span style=color:#ae81ff>5432</span>,
</span></span><span style=display:flex><span>    database<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;postgres&#34;</span>,
</span></span><span style=display:flex><span>    user<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;postgres&#34;</span>,
</span></span><span style=display:flex><span>    password<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;postgres&#34;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>engine <span style=color:#f92672>=</span> sqlalchemy<span style=color:#f92672>.</span>create_engine(connection_string)
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> engine<span style=color:#f92672>.</span>connect() <span style=color:#66d9ef>as</span> conn:
</span></span><span style=display:flex><span>    conn<span style=color:#f92672>.</span>execute(sqlalchemy<span style=color:#f92672>.</span>sql<span style=color:#f92672>.</span>text(<span style=color:#e6db74>&#39;CREATE EXTENSION IF NOT EXISTS vector; COMMIT;&#39;</span>))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.embeddings.openai <span style=color:#f92672>import</span> OpenAIEmbeddings
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>embeddings <span style=color:#f92672>=</span> OpenAIEmbeddings(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;text-embedding-ada-002&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>store <span style=color:#f92672>=</span> PGVector<span style=color:#f92672>.</span>from_documents(
</span></span><span style=display:flex><span>    embedding<span style=color:#f92672>=</span>embeddings,
</span></span><span style=display:flex><span>    documents<span style=color:#f92672>=</span>documents,
</span></span><span style=display:flex><span>    collection_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;wikipedia&#34;</span>,
</span></span><span style=display:flex><span>    connection_string<span style=color:#f92672>=</span>connection_string,
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>We can then search the vector database for the given articles that have the most relevance to the given query.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>query <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;Where was Alan Turing born and what is an Enigma machine?&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>store<span style=color:#f92672>.</span>similarity_search(query)
</span></span></code></pre></div><pre tabindex=0><code>[Document(page_content=&#39;Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n\nEarly life and family \nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.&#39;, metadata={&#39;id&#39;: &#39;130&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
 Document(page_content=&#39;Educated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.&#39;, metadata={&#39;id&#39;: &#39;133&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
 Document(page_content=&#39;A brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the&#39;, metadata={&#39;id&#39;: &#39;134&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
 Document(page_content=&#39;Education \nTuring went to St. Michael\&#39;s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n&#34;This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.&#39;, metadata={&#39;id&#39;: &#39;131&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;})]
</code></pre><h2 id=integrating-the-data-source-with-an-llm>Integrating the Data Source with an LLM</h2><p>Now we can wire up the LLM to use the Postgres vector database within a <code>RetrievalQA</code> chain.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chat_models <span style=color:#f92672>import</span> ChatOpenAI
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>llm <span style=color:#f92672>=</span> ChatOpenAI(
</span></span><span style=display:flex><span>    model_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gpt-3.5-turbo&#39;</span>,
</span></span><span style=display:flex><span>    temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>There are several different ways we can compile and ask the LLM the question.</p><h3 id=stuff>Stuff</h3><blockquote><p>The stuff documents chain (&ldquo;stuff&rdquo; as in &ldquo;to stuff&rdquo; or &ldquo;to fill&rdquo;) is the most straightforward of the document chains.
It takes a list of documents, inserts them all into a prompt and passes that prompt to an LLM.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> RetrievalQA
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> RetrievalQA<span style=color:#f92672>.</span>from_chain_type(
</span></span><span style=display:flex><span>    llm<span style=color:#f92672>=</span>llm,
</span></span><span style=display:flex><span>    chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stuff&#34;</span>,
</span></span><span style=display:flex><span>    retriever<span style=color:#f92672>=</span>store<span style=color:#f92672>.</span>as_retriever()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa<span style=color:#f92672>.</span>run(query)
</span></span></code></pre></div><blockquote><p>Alan Turing was born in Maida Vale, London.
An Enigma machine was a cipher machine used by the Nazi German military during World War II to encrypt and decrypt secret messages.
It was considered highly secure at the time and was used to protect sensitive communications. Turing played a crucial role in breaking the Enigma code, which greatly aided the Allied forces in their efforts during the war.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> RetrievalQAWithSourcesChain
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa_with_sources <span style=color:#f92672>=</span> RetrievalQAWithSourcesChain<span style=color:#f92672>.</span>from_chain_type(
</span></span><span style=display:flex><span>    llm<span style=color:#f92672>=</span>llm,
</span></span><span style=display:flex><span>    chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stuff&#34;</span>,
</span></span><span style=display:flex><span>    retriever<span style=color:#f92672>=</span>store<span style=color:#f92672>.</span>as_retriever()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa_with_sources(query)
</span></span></code></pre></div><pre tabindex=0><code>{&#39;question&#39;: &#39;Where was Alan Turing born and what is an Engima machine?&#39;,
 &#39;answer&#39;: &#39;Alan Turing was born in Maida Vale, London. An Enigma machine was a device designed by Turing at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine during World War 2.\n&#39;,
 &#39;sources&#39;: &#39;\n- https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}
</code></pre><h3 id=map-reduce>Map-Reduce</h3><blockquote><p>The map reduce documents chain first applies an LLM chain to each document individually (the Map step), treating the chain output as a new document.
It then passes all the new documents to a separate combine documents chain to get a single output (the Reduce step).</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains.question_answering <span style=color:#f92672>import</span> load_qa_chain
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> RetrievalQA(
</span></span><span style=display:flex><span>    combine_documents_chain<span style=color:#f92672>=</span>load_qa_chain(llm, chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;map_reduce&#34;</span>),
</span></span><span style=display:flex><span>    retriever<span style=color:#f92672>=</span>store<span style=color:#f92672>.</span>as_retriever()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa<span style=color:#f92672>.</span>run(query)
</span></span></code></pre></div><blockquote><p>The given portion of the document does not provide any information about where Alan Turing was born or what an Enigma machine is.</p></blockquote><p>Sadly, this type of chain does not seem to have returned the desired results.</p><h2 id=building-a-qa-chatbot>Building a Q&amp;A Chatbot</h2><p>We can also use the <code>ConversationalRetrievalChain</code> to build a chatbot that we can interact with to answer desired questions.
This includes adding a <em>memory</em>, allowing us to ask additional questions based on previous interactions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> ConversationalRetrievalChain
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.memory <span style=color:#f92672>import</span> ConversationBufferMemory
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>memory <span style=color:#f92672>=</span> ConversationBufferMemory(memory_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chat_history&#34;</span>, return_messages<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> ConversationalRetrievalChain<span style=color:#f92672>.</span>from_llm(llm, store<span style=color:#f92672>.</span>as_retriever(), memory<span style=color:#f92672>=</span>memory)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa({<span style=color:#e6db74>&#34;question&#34;</span>: <span style=color:#e6db74>&#34;Where was Alan Turing born?&#34;</span>})
</span></span><span style=display:flex><span>qa({<span style=color:#e6db74>&#34;question&#34;</span>: <span style=color:#e6db74>&#34;What year was he born?&#34;</span>})
</span></span></code></pre></div><pre tabindex=0><code>{&#39;question&#39;: &#39;What year was he born?&#39;,
 &#39;chat_history&#39;: [HumanMessage(content=&#39;Where was Alan Turing born?&#39;, additional_kwargs={}, example=False),
  AIMessage(content=&#39;Alan Turing was born in Maida Vale, London.&#39;, additional_kwargs={}, example=False),
  HumanMessage(content=&#39;What year was he born?&#39;, additional_kwargs={}, example=False),
  AIMessage(content=&#39;Alan Turing was born in 1912.&#39;, additional_kwargs={}, example=False)],
 &#39;answer&#39;: &#39;Alan Turing was born in 1912.&#39;}
</code></pre><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>qa <span style=color:#f92672>=</span> ConversationalRetrievalChain<span style=color:#f92672>.</span>from_llm(llm, store<span style=color:#f92672>.</span>as_retriever(), return_source_documents<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>qa({<span style=color:#e6db74>&#34;question&#34;</span>: query, <span style=color:#e6db74>&#34;chat_history&#34;</span>: []})
</span></span></code></pre></div><pre tabindex=0><code>{&#39;question&#39;: &#39;Where was Alan Turing born and what is an Engima machine?&#39;,
 &#39;chat_history&#39;: [],
 &#39;answer&#39;: &#39;Alan Turing was born in Maida Vale, London. \n\nAn Enigma machine was a cipher machine used by the Nazi German military during World War II to encrypt and decrypt secret messages. It was considered highly secure at the time and was used to protect sensitive communications. Turing played a crucial role in breaking the Enigma code, which greatly aided the Allied forces in their efforts during the war.&#39;,
 &#39;source_documents&#39;: [Document(page_content=&#39;Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n\nEarly life and family \nAlan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.&#39;, metadata={&#39;id&#39;: &#39;130&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
  Document(page_content=&#39;Educated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.&#39;, metadata={&#39;id&#39;: &#39;133&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
  Document(page_content=&#39;A brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the&#39;, metadata={&#39;id&#39;: &#39;134&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;}),
  Document(page_content=&#39;Education \nTuring went to St. Michael\&#39;s, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n&#34;This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.&#39;, metadata={&#39;id&#39;: &#39;131&#39;, &#39;source&#39;: &#39;https://simple.wikipedia.org/wiki/Alan%20Turing&#39;})]}
</code></pre><h3 id=adding-a-ui>Adding a UI</h3><p>Thanks to <a href=https://www.gradio.app/ rel="external noopener" target=_blank>Gradio</a>, we can front this chain with a simple chat UI.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span>pip install gradio
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> gradio <span style=color:#66d9ef>as</span> gr
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>memory <span style=color:#f92672>=</span> ConversationBufferMemory(memory_key<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chat_history&#34;</span>, return_messages<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>qa <span style=color:#f92672>=</span> ConversationalRetrievalChain<span style=color:#f92672>.</span>from_llm(llm, store<span style=color:#f92672>.</span>as_retriever(), memory<span style=color:#f92672>=</span>memory)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> gr<span style=color:#f92672>.</span>Blocks() <span style=color:#66d9ef>as</span> demo:
</span></span><span style=display:flex><span>    chatbot <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Chatbot()
</span></span><span style=display:flex><span>    msg <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Textbox()
</span></span><span style=display:flex><span>    clear <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>ClearButton([msg, chatbot])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>respond</span>(message, chat_history):
</span></span><span style=display:flex><span>        result <span style=color:#f92672>=</span> qa({<span style=color:#e6db74>&#34;question&#34;</span>: message})
</span></span><span style=display:flex><span>        chat_history<span style=color:#f92672>.</span>append((message, result[<span style=color:#e6db74>&#39;answer&#39;</span>]))
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;&#34;</span>, chat_history
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    msg<span style=color:#f92672>.</span>submit(respond, [msg, chatbot], [msg, chatbot])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>demo<span style=color:#f92672>.</span>launch()
</span></span></code></pre></div><p><picture><source type=image/webp srcset="/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_79702d60d05aa9a8.webp 350w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_55ba6e30d1643256.webp 700w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_15b2755ed4a1cbb9.webp 1258w"><source type=image/jpeg srcset="/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_5e3d227718e85c3a.jpg 350w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_31bb496b05b046c8.jpg 700w, /posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_de60e2e22b5ffa18.jpg 1258w"><img src=/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-postgres/chatbot_hu_31bb496b05b046c8.jpg alt=Chatbot loading=lazy></picture></p></main><footer class=post__tags><a href=/archive/tag/llm>llm</a><a href=/archive/tag/langchain>langchain</a><a href=/archive/tag/postgres>postgres</a></footer></article><div class="related-posts prose"><h3>Related Posts</h3><ul><li><a href=/posts/qa-retrieval-augmented-generation-rag-with-langchain-and-chroma/>Q&amp;A Retrieval Augmented Generation (RAG) with LangChain and Chroma</a></li></ul></div><div class=scroll-watcher></div></main><footer class="site-footer wrapper"><div>&copy; 2025, Edd Mann</div></footer><script>(function(){document.querySelector(".site-header__mobile-navigation-button").addEventListener("click",e=>{document.documentElement.classList.toggle("mobile-navigation-open"),e.target.setAttribute("aria-expanded",e.target.getAttribute("aria-expanded")==="false"?"true":"false")});const n=document.querySelector(".site-header");let t=window.pageYOffset,e=!1;window.addEventListener("scroll",()=>{if(e)return;setTimeout(()=>{const s=window.pageYOffset;n.classList.toggle("is-sticky",s>0&&t>s),t=s,e=!1},500),e=!0})})()</script></body></html>